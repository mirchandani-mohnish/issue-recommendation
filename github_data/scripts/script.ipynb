{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNAzzy Link Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 \n",
    "- Import Libraries \n",
    "- Import the Graph\n",
    "- Draw a sample of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m edgeCountForDisplay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     gph \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_gexf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphFile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     helper_methods\u001b[38;5;241m.\u001b[39mlogData(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph file found at \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m())\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/utils/decorators.py:766\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(\u001b[39m*\u001b[39margs, __wrapper\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m argmap\u001b[39m.\u001b[39;49m_lazy_compile(__wrapper)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 5:5\u001b[0m, in \u001b[0;36margmap_read_gexf_1\u001b[0;34m(path, node_type, relabel, version)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgzip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m defaultdict\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/readwrite/gexf.py:175\u001b[0m, in \u001b[0;36mread_gexf\u001b[0;34m(path, node_type, relabel, version)\u001b[0m\n\u001b[1;32m    173\u001b[0m     G \u001b[39m=\u001b[39m relabel_gexf_graph(reader(path))\n\u001b[1;32m    174\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     G \u001b[39m=\u001b[39m reader(path)\n\u001b[1;32m    176\u001b[0m \u001b[39mreturn\u001b[39;00m G\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/readwrite/gexf.py:695\u001b[0m, in \u001b[0;36mGEXFReader.__call__\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    693\u001b[0m g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxml\u001b[39m.\u001b[39mfind(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNS_GEXF\u001b[39m}\u001b[39;00m\u001b[39m}}\u001b[39;00m\u001b[39mgraph\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    694\u001b[0m \u001b[39mif\u001b[39;00m g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_graph(g)\n\u001b[1;32m    696\u001b[0m \u001b[39m# try all the versions\u001b[39;00m\n\u001b[1;32m    697\u001b[0m \u001b[39mfor\u001b[39;00m version \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversions:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/readwrite/gexf.py:773\u001b[0m, in \u001b[0;36mGEXFReader.make_graph\u001b[0;34m(self, graph_xml)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[39mif\u001b[39;00m edges_element \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[39mfor\u001b[39;00m edge_xml \u001b[39min\u001b[39;00m edges_element\u001b[39m.\u001b[39mfindall(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNS_GEXF\u001b[39m}\u001b[39;00m\u001b[39m}}\u001b[39;00m\u001b[39medge\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 773\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_edge(G, edge_xml, edge_attr)\n\u001b[1;32m    775\u001b[0m \u001b[39m# switch to Graph or DiGraph if no parallel edges were found.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimple_graph:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/readwrite/gexf.py:909\u001b[0m, in \u001b[0;36mGEXFReader.add_edge\u001b[0;34m(self, G, edge_element, edge_attr)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_edge\u001b[39m(\u001b[39mself\u001b[39m, G, edge_element, edge_attr):\n\u001b[1;32m    905\u001b[0m     \u001b[39m# add an edge to the graph\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \n\u001b[1;32m    907\u001b[0m     \u001b[39m# raise error if we find mixed directed and undirected edges\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     edge_direction \u001b[39m=\u001b[39m edge_element\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 909\u001b[0m     \u001b[39mif\u001b[39;00m G\u001b[39m.\u001b[39;49mis_directed() \u001b[39mand\u001b[39;00m edge_direction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mundirected\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    910\u001b[0m         \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mNetworkXError(\u001b[39m\"\u001b[39m\u001b[39mUndirected edge found in directed graph.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    911\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m G\u001b[39m.\u001b[39mis_directed()) \u001b[39mand\u001b[39;00m edge_direction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdirected\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/classes/multigraph.py:1015\u001b[0m, in \u001b[0;36mMultiGraph.is_directed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns True if graph is a multigraph, False otherwise.\"\"\"\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 1015\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_directed\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1016\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns True if graph is directed, False otherwise.\"\"\"\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import utils.helper_methods as helper_methods\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "graphFile = \"../graphs/v3/contribConnected.gexf\"\n",
    "edgeCountForDisplay = 30\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    gph = nx.read_gexf(graphFile)\n",
    "    helper_methods.logData(\"graph file found at \" + str())\n",
    "except Exception as e:\n",
    "    helper_methods.logData(e)\n",
    "    gph = nx.Graph()\n",
    "    helper_methods.logData(\"new graph file generated\")\n",
    "\n",
    "\n",
    "\n",
    "sampleNodeList = []\n",
    "sampleEdgeList = []\n",
    "userList = []\n",
    "for n in gph.nodes(data = True):\n",
    "    sampleNodeList.append(str(n[0]))\n",
    "    \n",
    "    if(n[1]['bipartite'] == 0):\n",
    "        userList.append(str(n[0]))\n",
    "    \n",
    "    edgeCountForDisplay -= 1\n",
    "    if(edgeCountForDisplay == 0):\n",
    "        break\n",
    "\n",
    "\n",
    "# subgraph_nodes = [1, 2, 'a', 'b', 'c', 'd', 'e', 'f']\n",
    "subgraph = gph.subgraph(sampleNodeList)        \n",
    "pos = nx.bipartite_layout(subgraph, userList)\n",
    "nx.draw(subgraph, pos, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Jaccard Coefficient Method \n",
    "A method of link prediction based on common neighbours. \n",
    "'''\n",
    "Jaccard Coefficient = (Number of Common Neighbours)/(Total Number of Neighbours)\n",
    "'''\n",
    "\n",
    "It provides link prediction based on the computation of the above score. \n",
    "\n",
    "Recommendations: The Algorithm proves to be quick with a complexity of (n^2) but proves to be less accurate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = gph\n",
    "\n",
    "users = [n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 0]\n",
    "issues = [n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def jaccard_coefficient(graph, node1, node2):\n",
    "    neighbors1 = set(graph.neighbors(node1))\n",
    "    neighbors2 = set(graph.neighbors(node2))\n",
    "    intersection = neighbors1.intersection(neighbors2)\n",
    "    union = neighbors1.union(neighbors2)\n",
    "    if len(union) == 0:\n",
    "        return 0\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "\n",
    "def jaccard_link_prediction(graph, threshold):\n",
    "    predicted_edges = []\n",
    "    count = 10000\n",
    "    userCount = 0\n",
    "    for node1 in users:\n",
    "        \n",
    "        userCount += 1\n",
    "        if(userCount%100 == 0):\n",
    "            print(userCount)\n",
    "        for node2 in issues:\n",
    "            \n",
    "            if node1 == node2 or graph.has_edge(node1, node2):\n",
    "                continue\n",
    "            \n",
    "            jaccard = jaccard_coefficient(graph, node1, node2)\n",
    "            if(jaccard >=threshold):\n",
    "                \n",
    "                predicted_edges.append((node1, node2, jaccard))\n",
    "                count -= 1\n",
    "                if(count == 0):\n",
    "                    print(node1,end=\"-------\")\n",
    "                    print(node2, end=\"-------\")\n",
    "                    print(jaccard)\n",
    "                    count = 10000\n",
    "                    \n",
    "    return sorted(predicted_edges, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Adamic Adar \n",
    "Adamic Adar is a link prediction algorithm which uses the similarity of nodes as an underlying pretext. It assigns a similarity score to a pair of nodes based on the number of shared neighbors they have, with the contribution of each neighbor weighted by its degree\n",
    "\n",
    "'''\n",
    "Initialize the Adamic-Adar score to 0:\n",
    "score = 0\n",
    "\n",
    "For each common neighbor w:\n",
    "for w in common_neighbors:\n",
    "\n",
    "Compute the logarithmic degree of node w\n",
    "If the degree of node w is greater than 1 add the reciprocal of the logarithmic degree to the score:\n",
    "if degree != 0:\n",
    "            score += 1 / np.log(degree)\n",
    "\n",
    "Return the final Adamic-Adar similarity score between nodes u and v:\n",
    "return score\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Recommendation: Adamic Adar provides slightly better results because it considers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamic_adar(u, v, G):\n",
    "    neighbors = list(nx.common_neighbors(G, u, v))\n",
    "    score = 0\n",
    "    for w in neighbors:\n",
    "        degree = G.degree(w)\n",
    "        if degree != 0:\n",
    "            score += 1 / np.log(degree)\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "similarity_scores = {}\n",
    "for u in users:\n",
    "    for v in issues:\n",
    "        if not gph.has_edge(u, v):\n",
    "            score = adamic_adar(u, v, B)\n",
    "            similarity_scores[(u, v)] = score\n",
    "\n",
    "# Sort the similarity scores in descending order\n",
    "sorted_scores = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Preferential Attachment \n",
    "Preferential Attachment score uses neighbours to give a value which essentially runs on the \"Rich Getting Richer\" theorem where two nodes with higher degree should have a greater chance of connection and thus prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_nodes = [n for n in test.nodes() if test.nodes[n]['bipartite'] == 0]\n",
    "user_nodes = [n for n in test.nodes() if test.nodes[n]['bipartite'] == 1]\n",
    "\n",
    "def preferential_attachment(G, issue, user):\n",
    "    issue_neighbors = set(G.neighbors(issue))\n",
    "    user_neighbors = set(G.neighbors(user))\n",
    "    return len(issue_neighbors) * len(user_neighbors)\n",
    "\n",
    "\n",
    "def prefAttach(gph, threshold):\n",
    "    predicted = []\n",
    "    for issue in issue_nodes:\n",
    "        for user in user_nodes:\n",
    "            if gph.has_edge(user, issue):\n",
    "                continue\n",
    "            score = preferential_attachment(gph, issue, user)\n",
    "            if (score>=threshold):\n",
    "                predicted.append((issue, user, score))\n",
    "    return sorted(predicted, key=lambda x: x[2], reverse=True)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Resource Allocation \n",
    "Resource allocation essentially measures how \"Resourceful\" a node is. It adds a score to every node based on the degree of its neighbours.\n",
    "- The rationale behind using the inverse of the degree is that nodes with higher degrees are considered to have more resources or connections, and thus, the resources they can allocate to any one neighbor may be relatively lower compared to nodes with lower degrees. Therefore, by taking the inverse of the degree, the algorithm gives higher scores to pairs of nodes that share common neighbors with lower degrees, which are assumed to be more valuable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m C\u001b[38;5;241m=\u001b[39m \u001b[43mB\u001b[49m\n",
      "\u001b[1;32m      3\u001b[0m usersC \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n, d \u001b[38;5;129;01min\u001b[39;00m C\u001b[38;5;241m.\u001b[39mnodes(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbipartite\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;32m      4\u001b[0m issuesC \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n, d \u001b[38;5;129;01min\u001b[39;00m C\u001b[38;5;241m.\u001b[39mnodes(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbipartite\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "C= B\n",
    "\n",
    "usersC = [n for n, d in C.nodes(data=True) if d[\"bipartite\"] == 0]\n",
    "issuesC = [n for n, d in C.nodes(data=True) if d[\"bipartite\"] == 1]\n",
    "\n",
    "\n",
    "# Resource Allocation\n",
    "\n",
    "C=B\n",
    "# Initialize sets for each partition\n",
    "setA = set()\n",
    "setB = set()\n",
    "setAll= set()\n",
    "count = 50\n",
    "\n",
    "# Iterate through the graph and populate sets for each partition\n",
    "for n in C.nodes(data = True):\n",
    "    setAll.add(str(n[0]))\n",
    "    \n",
    "    if(n[1]['bipartite'] == 0):\n",
    "        setA.add(str(n[0]))\n",
    "    else:\n",
    "        setB.add(str(n[0]))\n",
    "    # count -= 1\n",
    "    # if(count == 0):\n",
    "    #     break\n",
    "    \n",
    "\n",
    "\n",
    "for u in C:\n",
    "        for v in C[u]:\n",
    "            if u==v or (u not in usersC):\n",
    "                  continue\n",
    "            print(f\"Edge: {u} - {v}\")\n",
    "\n",
    "\n",
    "\n",
    "C_edges = []\n",
    "for u in C:\n",
    "        for v in C[u]:\n",
    "            if u==v or (u not in usersC):\n",
    "                  continue\n",
    "            #print(f\"Edge: {u} - {v}\")\n",
    "            C_edges.append((u,v))\n",
    "\n",
    "# print(C_edges)\n",
    "i=0;\n",
    "for u in C_edges:\n",
    "        if i<10:\n",
    "               print(f\"Edge: {u}\")\n",
    "               i=i+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resource_allocation(G, u, v):\n",
    "    neighbors_u = set(G[u])\n",
    "    neighbors_v = set(G[v])\n",
    "    common_neighbors = neighbors_u.intersection(neighbors_v)\n",
    "    score = 0\n",
    "    for neighbor in common_neighbors:\n",
    "        degree = len(list(G.neighbors(neighbor))) ### check this ....\n",
    "        score += 1 / degree\n",
    "    return score\n",
    "\n",
    "# Compute resource allocation scores for all pairs of nodes in set A and set B\n",
    "predicted_edges = []\n",
    "for u in setA:\n",
    "    for v in setB:\n",
    "        if not C.has_edge(u, v):\n",
    "            score = resource_allocation(C, u, v)\n",
    "            predicted_edges.append((u, v, score))\n",
    "\n",
    "# Sort the predicted edges by resource allocation score in descending order\n",
    "predicted_edges.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Print the top 3 predicted edges with the highest resource allocation scores\n",
    "print(\"Top 10 Predicted Edges:\")\n",
    "for i in range(10):\n",
    "    print(f\"Edge: {predicted_edges[i][0]} - {predicted_edges[i][1]}, Resource Allocation Score: {predicted_edges[i][2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backing Behind Algo\n",
    "- we first run through graph \n",
    "- for every user\n",
    "    - we see the issues i[n] connected to the user suppose u1\n",
    "    - for issue in i[n]\n",
    "        - traverse neighbours of issues\n",
    "        - add a weight of 1\n",
    "        [ for common neighbours, the weights would increment to more than 1 ]\n",
    "    - for every neighbour(user) user_neigh of this user based on contributions\n",
    "        - for every issue of user_neigh\n",
    "            - add a weight of 2 to issue\n",
    "    - for every neighbour(user) user_neigh of this user based on starred \n",
    "        - for every issue of user_neigh\n",
    "            - add a weight of 1 to issue and neighbours\n",
    "    - go through weights for the issues\n",
    "    - add issues with weight over k ( threshold ) into the array.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {}\n",
    "contributions = set() # all nodes with type contribution\n",
    "starred = set() # all nodes with type starred repo\n",
    "\n",
    "for n in gph.nodes(data = True):\n",
    "    if n[1]['bipartite'] == 0:\n",
    "        values[n[0]] = 1\n",
    "    else:\n",
    "        values[n[0]] = 2\n",
    "\n",
    "for n in gph.edges(data = True):\n",
    "    if 'contributions' in n[2]:\n",
    "        contributions.add(n[0])\n",
    "        contributions.add(n[1])\n",
    "    else:\n",
    "        starred.add(n[0])\n",
    "        starred.add(n[1])\n",
    "\n",
    "# users -> 1\n",
    "# issues -> 2\n",
    "# contribution -> 3\n",
    "# starred -> 4\n",
    "\n",
    "threshold = 3\n",
    "predicted = []\n",
    "\n",
    "for node in gph.nodes():\n",
    "\n",
    "    if values[node] == 1: # if it is user\n",
    "        current_user = node\n",
    "        weight = {} # to store weights of issues\n",
    "        prediction = []\n",
    "        for nodes in gph.neighbors(current_user):\n",
    "            if values[nodes] == 2: # issues connected to users\n",
    "                issues = nodes\n",
    "                for issue_neigh in gph.neighbors(issues): # neighbours of issues connected to users\n",
    "                    if values[issue_neigh] == 2:\n",
    "                        if issue_neigh in weight:\n",
    "                            weight[issue_neigh] += 1\n",
    "                        else:\n",
    "                            weight[issue_neigh] = 1\n",
    "            else: # users connected to users\n",
    "                user = nodes\n",
    "                if user in contributions: # if user is connected via contribution\n",
    "                    for issue_neigh in gph.neighbors(user): # issues that are neighbours of users connected to cuurent user \n",
    "                        if values[issue_neigh] == 2:\n",
    "                            if issue_neigh in weight:\n",
    "                                weight[issue_neigh] += 2\n",
    "                            else:\n",
    "                                weight[issue_neigh] = 2\n",
    "                else: # if user is connected via starred repo\n",
    "                    for issue_neigh in gph.neighbors(user): # issues that are neighbours of users connected to cuurent user\n",
    "                        if values[issue_neigh] == 2:\n",
    "                            if issue_neigh in weight:\n",
    "                                weight[issue_neigh] += 1\n",
    "                            else:\n",
    "                                weight[issue_neigh] = 1\n",
    "        \n",
    "        Issues = list(weight.keys())\n",
    "        Weights = list(weight.values())\n",
    "\n",
    "        # print(current_user, end = \" --> \")\n",
    "        # Probability = Element Weight / Sum Of All Weights\n",
    "        predicted_issue = random.choices(Issues, Weights, k = 1)[0]\n",
    "        # print(predicted_issue) # k is the number of outputs\n",
    "        \n",
    "        predicted.append([current_user, predicted_issue])\n",
    "\n",
    "for i in predicted:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
